{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c2506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import spacy\n",
    "\n",
    "from funer.document import Document\n",
    "from funer.annotators.dictionary_annotator import DictionaryAnnotator\n",
    "from funer.annotators.token_condition_annotator import (\n",
    "    TokensConditionAnnotator, generate_token_conditions_function)\n",
    "from funer.annotators.span_condition_annotator import SpanConditionAnnotator\n",
    "from funer.document import Document\n",
    "from funer.labeling_function_applier import LabelingFunctionApplier\n",
    "from funer.aggregators.majority_voting_aggregators import MajorityVotingAggregator\n",
    "from funer.utils import show_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e750aaec",
   "metadata": {},
   "source": [
    "## Create documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3bd5608",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "labeled_document_1 = Document.from_spacy_doc(\n",
    "    nlp(\"Donald John Trump was born in New York.\"),\n",
    "    gold_entities=[\n",
    "        (0, 17, \"PER\"), # Donald John Trump\n",
    "        (30, 38, \"LOC\") # New York\n",
    "    ]\n",
    ")\n",
    "labeled_document_2 = Document.from_spacy_doc(\n",
    "    nlp(\"Abe Rosenthal was editor-in-chief of the New York Times in 1998.\"),\n",
    "    gold_entities=[\n",
    "        (0, 13, \"PER\"),   # Abe Rosenthal\n",
    "        (41, 55, \"ORG\"),  # New York Times\n",
    "        (59, 63, \"DATE\"), # 1998\n",
    "    ]\n",
    ")\n",
    "nolabeled_document = Document.from_spacy_doc(\n",
    "    nlp(\"I want to go to New York.\"),\n",
    ")\n",
    "documents = [labeled_document_1, labeled_document_2, nolabeled_document]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d1a2c",
   "metadata": {},
   "source": [
    "### Option: Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca7c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_labeled_document_1 = Document(\n",
    "    tokens=['Donald', 'John', 'Trump', 'was', 'born', 'in', 'New', 'York', '.'],\n",
    "    spaces=[True, True, True, True, True, True, True, False, False],\n",
    "    gold_label=['B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521f076",
   "metadata": {},
   "source": [
    "## Labeling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee09054",
   "metadata": {},
   "source": [
    "### Define  Labeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5e0d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1: Per-token labeling function\n",
    "def detect_name(tokens):\n",
    "    for i in range(len(tokens) - 3):\n",
    "        if tokens[i:i + 3] == [\"Donald\", \"John\", \"Trump\"]:\n",
    "            yield i, i + 3\n",
    "f1 = TokensConditionAnnotator(\n",
    "    name=\"person_f\",\n",
    "    f=detect_name,\n",
    "    label=\"PER\"\n",
    ")\n",
    "\n",
    "# f2: Per-token labeling function using generate_token_conditions_function\n",
    "f2 = TokensConditionAnnotator(\n",
    "    name=\"year_f\",\n",
    "    f=generate_token_conditions_function([\n",
    "        lambda token_1: re.search(r\"(19|20)\\d{2}\", token_1) is not None,\n",
    "    ]),\n",
    "    label=\"DATE\"\n",
    ")\n",
    "\n",
    "# f3: Per-character labeling functions\n",
    "def span_condition_function(text: str):\n",
    "    for m in re.finditer(r\"Abe Rosenthal\", text):\n",
    "        yield m.start(), m.end()\n",
    "f3 = SpanConditionAnnotator(\n",
    "    name=\"person_f2\",\n",
    "    f=span_condition_function,\n",
    "    label=\"PER\"\n",
    ")\n",
    "\n",
    "\n",
    "# f4: Labeling functions with dictionary\n",
    "#   : (Note) Example of mistakenly extracting New York of New York Times as LOC\n",
    "loc_dictionary = [\"New York\", \"Minneapolis\"]\n",
    "f4 = DictionaryAnnotator(\n",
    "    name=\"city_f\",\n",
    "    words=loc_dictionary,\n",
    "    label=\"LOC\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d4022",
   "metadata": {},
   "source": [
    "### Apply of labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c22c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens       Donald   John    Trump   was   born   in   New     York    .\n",
      "=========================================================================\n",
      "gold_label   B-PER    I-PER   I-PER   O     O      O    B-LOC   I-LOC   O\n",
      "-------------------------------------------------------------------------\n",
      "person_f     B-PER    I-PER   I-PER   O     O      O    O       O       O\n",
      "city_f       O        O       O       O     O      O    B-LOC   I-LOC   O\n",
      "-------------------------------------------------------------------------\n",
      "aggregate    B-PER    I-PER   I-PER   O     O      O    B-LOC   I-LOC   O\n",
      "\n",
      "tokens       I   want   to   go   to   New     York    .\n",
      "========================================================\n",
      "gold_label   -   -      -    -    -    -       -       -\n",
      "--------------------------------------------------------\n",
      "city_f       O   O      O    O    O    B-LOC   I-LOC   O\n",
      "--------------------------------------------------------\n",
      "aggregate    O   O      O    O    O    B-LOC   I-LOC   O\n"
     ]
    }
   ],
   "source": [
    "# Applying the labeling function\n",
    "lf_applier = LabelingFunctionApplier(lfs=[f1, f2, f3, f4])\n",
    "documents = lf_applier.apply(documents)\n",
    "\n",
    "# Integration of labeling results\n",
    "aggregator = MajorityVotingAggregator()\n",
    "documents = aggregator.aggregate(documents)\n",
    "\n",
    "# Output Results\n",
    "print(show_labels(documents[0]))\n",
    "print()\n",
    "print(show_labels(documents[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5e661b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_name    | pos | neg | hit\n",
      "==========+=====+=====+====\n",
      "person_f  | 1   | 0   | 1  \n",
      "year_f    | 1   | 0   | 1  \n",
      "person_f2 | 1   | 0   | 1  \n",
      "city_f    | 1   | 1   | 2  \n"
     ]
    }
   ],
   "source": [
    "print(lf_applier.show_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e52941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EntitySpan(start_offset=16, end_offset=24, label='LOC')]\n"
     ]
    }
   ],
   "source": [
    "print(documents[2].export_span_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e426b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(documents[2].export_bio_label())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
